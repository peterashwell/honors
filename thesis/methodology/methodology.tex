%\documentclass[10pt]{report}
%
%\usepackage[margin=2.5cm]{geometry}
%\usepackage{tikz}
%\usetikzlibrary{shapes,arrows}
%\usepackage{amsmath}
%\usepackage{array}
%\usepackage{subfigure}
%\usepackage[colorlinks=true,linkcolor=blue]{hyperref}
%\usepackage[all]{hypcap}
%\usepackage{lscape}
%\usepackage{multirow}
%\usepackage[utf8]{inputenc}
%\usepackage[T1]{fontenc}
%\usepackage{algorithmic}
%\usepackage{algorithm}
%\usepackage{rotating}
%\setlength{\parindent}{0in}
%
%%\title{Experimental setup and data conditions}
%
%\date{}
%
%\begin{document}
	\chapter{Experimental set-up and data simulation}
    
	\section{Introduction}

%	\begin{itemize}
%		\item purpose - classify transients
%		\item use transient definition from elsewhere
%		\item outline transient types
%		\item mention data simulation
%		\item mention data distortions
%		\item outline experimental quality with reference to above
%	\end{itemize}
%		
%		\begin{itemize}
%			\item ASKAP is not yet online
%			\item Little real world data is available
%			\item Solution: simulate
%			\item Simulation will also attempt to model the distortions present in survey data
%			\item Transients simulated should be similar in structure to real world transients, not necessarily exactly the same. Needs to challenge classification algorithms in the same way the real light curve would
%			\item Distortions need to be introduced into the data carefully so that experimental results are meaningful
%			\item An accurate simulation of real world telescope data will allow the effectiveness of classification algorithms to be evaluated, potentially for use in the VAST project.
%		\end{itemize}
		
		The question to be addressed by this research is how effective time series classification algorithms will be on the data collected by the ASKAP telescope array. ASKAP will not be online until 2012 and there are no other survey datasets that make a useful substitute. Instead of real data then, simulated time series based on models of transient events will be used to assess classifiers. These models will not perfectly represent real world transients, but will be sufficiently similar so as to challenge the classification algorithm in the same way. The data quality issues that complicate classification will also be simulated, and this needs to be done carefully to ensure the results are meaningful. By modifying the type and severity of the distortions in the simulated data, knowledge about the practical classification of survey classification can be gained. This understanding of the complications of on-line classification will inform algorithm choices in the VAST pipeline. % TODO add references
	
	\section{Transient types}
		Six types of transients are being simulated, including the non-periodic Extreme Scattering Events (ESEs), Flares, Supernovae (SNe), Novae, X-Ray binaries,  and the periodic Intra-Day Variables (IDVs). These are combined with `non-transients' represented by a flat signal with noise added. 100 of each of these light curves will form an experimental data set. Figure below shows a typical simulated light curve of each type. See the appendix for details on the models used to produce each light curve. % TODO reference appendix and figure
	
	\begin{figure}[ht!]
		\centering
		Placeholder for transient types
		\caption{The 6 transient types and non-transient \emph{noise} class}
	\end{figure}
	
	Examples of some real-world data representing these transient types are in figure . % TODO add figure
	
	\begin{figure}[ht!]
		\centering
		Placeholder for real world transients
		\caption{Real world transient time series}
	\end{figure}
	
	These classes do not represent all the potential transients that could arise in reality, nor are they completely accurate representations. Their structures however are sufficiently similar to the real thing to  afford a preliminary investigation into the difficulties of machine-learned classification.
		
	\section{Data quality variables}
		In order to examine the performance of classifiers in terms of the different data quality issues present in the real world, classification will be attempted with a variety of distortions applied, both one at a time, and simultaneously.
		\begin{table*}[ht!]
			\centering
			$
			\begin{array}{lp{0.7\textwidth}}
			\textbf{Incompleteness} & Data arrives as a stream and early classification is important. Varying the percentage of the total light curve that is available is important for assessing the viability of on-line classification.
			\vspace{10pt} \\
			\textbf{Noise} & Noise is a consistent factor in telescope observation. Signal noise results from atmospheric distortions, intrinsic equipment inaccuracy, and objects in the interstellar medium that interrupt light from distant objects.
			\vspace{10pt} \\
			\textbf{Missing data} & Due to poor weather conditions or competing demands on telescope time, some data will simply not be available. Missing data will typically appear in small chunks (5-10\%) of the full dataset, randomly distributed.
			\vspace{10pt} \\
			\textbf{Amplitude scaling} & Due to the distribution of stellar events, as well as intrinsic differences in the brightness of these events, the actual intensity of points in the signal is not meaningful, \emph{only the intensity of a point relevant to the other points in the signal}. The average intensity of observed signals corresponds roughly to a -2.3 power law distribution. This will be compared to light curves which are centered (mean subtracted and divided by their standard deviation) to examine the effect that the power law distribution has on the classification effectiveness.
			\vspace{10pt} \\  % TODO add reference for powlaw paper
			\textbf{Signal variation} & All the light curves used in classification will have variation in the way in that the light curves unfold. For light curves that are better defined by their shapes such as ESEs, differences in the strengths of slopes, time between maxima and minima will change. Periodic signals such as IDVs will have differences (but also similarities) in their characteristic frequency spectra. It is not possible to easily change or quantify the amount of variability within the dataset, but both differences in underlying frequency and structure will be present.
			\vspace{10pt} \\
			\end{array}
			$
			\caption{Data quality conditions}
		\end{table*}
		Classification performance will be analysed in terms of precision, recall and F-score by varying each of these signals individually and altogether. It is likely that the combination of multiple distortions will compound the individual losses in classification performance.
		
		
		
	\section{Implementation details}
		The order in which multiple distortions are applied is important, and the exact way distortions are applied within each class must be carefully done to ensure to ensure there is no unusual influence on the results. Distortions are applied in the order and with the options outlined in the table below. The output of step $n$ is fed into step $n + 1$.
		
		\begin{table}[ht!]
		\centering
		\begin{tabular}{|c|l|p{0.6\textwidth}|} \hline
			\textbf{Step} &\textbf{Distortion type} & \textbf{Amounts used} \\ \hline
			0 & Raw signal from model & \emph{none} \\
			1 & Distribution type & Either \emph{centered} or \emph{-2.3 power law} \\
			2 & Noise & 0, 0.5, 1, 1.5 or 3 times the signal standard deviation as gaussian distributed noise\\
			3 & Signal available & 10, 20, 30, 50, 70, 90\% of light curve data \\
			4 & Gapify signal & 10, 20, 30, 50, 70, 90\% of signal randomly as 1, 2, 5\% chunks \\
			5 & Stratification and classification & \emph{none} \\ \hline
		\end{tabular}
		\caption{Details of data distortion introduction}
		\end{table}
		
		\subsection{Simulating a power law distribution}
		Centered is performed by subtracting the mean from the light curve and dividing by its standard deviation. The original signal should have no outlier points or noise so this should remove amplitude scaling as a factor in classification. \\
		The power law is implemented by drawing random numbers uniformly between $a_{l}^{-2.3}$ and $a_{h}^{-2.3}$, where these values indicate the lower and upper bounds of the amplitudes desired in the power law distribution. The random value so drawn taken to the power -2.3 giving an amplitude in the desired range with values probability distribution corresponding to the power law. %  TODO tidy this up and write discussion section \\
		
		\begin{figure}
			\label{fig:powlaw_sample.eps}
			Placeholder for figure of power law distribution application
			\caption{Effect of applying the power law distribution to a light curve}
		\end{figure}
		
		\subsection{Add noise to signal ratio}
		Noise will be introduced into the signal by computing the signal variance and adding gaussian noise to 0.5, 1, 1.5 or 3 times that amount on top of the signal. \\ \\
%		TODO move this discussion to sec 2 Astronomers regard signals with intensity at 5 times the expected noise to be significant. Introducing in accordance to variance seems to be a good way to replicate this condition of a 'meaningful' signal in an experimental context. A more natural way in terms of survey data to introduce noise would be to add a constant noise amount such that in a power law distribution bright signals appear clearly, and softer signals blend into the background noise and are indistinguishable. For the purposes of this experiment we wish to examine the effects of noise on classification in general and on each class, and this is difficult when the random distribution of signal amplitudes will interfere with their ability to be classified.
		
		\begin{figure}
			\label{fig:noise_sample.eps}
			Placeholder for figure of noise addition
			\caption{Effect of applying the noise distortion to a light curve}
		\end{figure}
		
		\subsection{Removing part of the signal}
		This step is very straightforward. The latter $k\%$ of the signal is discarded and only the first part kept.
		
		\begin{figure}
			\label{fig:observe_sample.eps}
			Placeholder for figure of removing part of the signal
			\caption{Effect of applying the on-line distortion to the signal}
		\end{figure}
		
		\subsection{Introducing gaps into the signal}
		This part must be done after a contiguous chunk of the signal is removed as in the previous step. This involves discarding randomly sized chunks at 1, 2, or 5\% of total signal length (before step 3) at random locations, until the desired amount of data has been taken out. The procedure does not guarantee that the chunks so removed will not overlap (so larger contiguous sections may be removed than the individual chunks.  % TODO sampling approaches
		
		\begin{figure}
			\label{fig:missing_sample.eps}
			Placeholder for introducing gaps into the signal
			\caption{Effect of applying the missing data distortion to the signal}
		\end{figure}
		
		% TODO add methodology
		% RANDOM FOREST
%\end{document}
